{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/botatooo/pp-detection-fracture-recherche/blob/dev/src/fracatlas_efficientdet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
      ],
      "metadata": {
        "id": "xaehsA6usXtQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
      ],
      "metadata": {
        "id": "Ynemyv6St0De",
        "outputId": "e0c10a8e-e75c-4ed1-e7a3-f51ecafec887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.1 ; cuda:  cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from torchvision.datasets.utils import download_and_extract_archive\n",
        "\n",
        "root = \"dataset/\"\n",
        "url = \"https://figshare.com/ndownloader/files/41725659\"\n",
        "filename = \"fracatlas.zip\"\n",
        "\n",
        "# if download:\n",
        "if not os.path.isdir(os.path.join(root, \"FracAtlas\")):\n",
        "    os.makedirs(root, exist_ok=True)\n",
        "    download_and_extract_archive(\n",
        "        url,\n",
        "        os.path.dirname(root),\n",
        "        filename=filename,\n",
        "        remove_finished=True,\n",
        "    )\n",
        "if not os.path.isdir(root):\n",
        "    raise RuntimeError(\n",
        "        \"Dataset not found or corrupted. You can use download=True to download it\"\n",
        "    )\n",
        "\n",
        "with open(\"dataset/FracAtlas/Annotations/COCO JSON/COCO_fracture_masks.json\") as f:\n",
        "  fracture_masks_data = json.load(f)\n",
        "\n",
        "fractured_images = [i[\"file_name\"] for i in fracture_masks_data[\"images\"]]\n",
        "fractured_image_count = len(fractured_images)\n",
        "\n",
        "training_images = fracture_masks_data[\"images\"][: int(0.9 * fractured_image_count)]\n",
        "testing_images = fracture_masks_data[\"images\"][int(0.9 * fractured_image_count) :]\n",
        "\n",
        "os.mkdir(\"data\")\n",
        "\n",
        "\n",
        "os.mkdir(\"data/images\")\n",
        "os.mkdir(\"data/images/train2017\")\n",
        "for i in training_images:\n",
        "  full_path = os.path.abspath(os.path.join(\"dataset/FracAtlas/images/Fractured\", i[\"file_name\"]))\n",
        "  new_path = os.path.abspath(os.path.join(\"data/images/train2017\", i[\"file_name\"]))\n",
        "  os.rename(full_path, new_path)\n",
        "\n",
        "os.mkdir(\"data/images/val2017\")\n",
        "for i in testing_images:\n",
        "  full_path = os.path.abspath(os.path.join(\"dataset/FracAtlas/images/Fractured\", i[\"file_name\"]))\n",
        "  new_path = os.path.abspath(os.path.join(\"data/images/val2017\", i[\"file_name\"]))\n",
        "  os.rename(full_path, new_path)\n",
        "\n",
        "os.mkdir(\"data/annotations\")\n",
        "with open(\"data/annotations/instances_train2017.json\", \"w\") as f:\n",
        "  json.dump({\n",
        "      'info': {'description': 'my-project-name'},\n",
        "      'images': training_images,\n",
        "      'categories': [{'id': 0, 'name': 'fractured'}]\n",
        "  }, f)\n",
        "with open(\"data/annotations/instances_val2017.json\", \"w\") as f:\n",
        "  json.dump({\n",
        "      'info': {'description': 'my-project-name'},\n",
        "      'images': testing_images,\n",
        "      'categories': [{'id': 0, 'name': 'fractured'}]\n",
        "  }, f)\n"
      ],
      "metadata": {
        "id": "vMpgngfkrc0s",
        "outputId": "0fee12e5-ef4f-490a-ba88-6977eba1e70e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/41725659/FracAtlas.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20240111/eu-west-1/s3/aws4_request&X-Amz-Date=20240111T045636Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=0dca07130d30de7d4203f63beada061d170c2e84b4867295f2893d858d232c86 to dataset/fracatlas.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 338412751/338412751 [00:03<00:00, 99813029.28it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/fracatlas.zip to dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/toandaominh1997/EfficientDet.Pytorch efficientdet\n",
        "%cd efficientdet"
      ],
      "metadata": {
        "id": "RadH28jRwCKc",
        "outputId": "d6d01347-062d-4929-98f2-f96d37985d47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'efficientdet'...\n",
            "remote: Enumerating objects: 791, done.\u001b[K\n",
            "remote: Total 791 (delta 0), reused 0 (delta 0), pack-reused 791\u001b[K\n",
            "Receiving objects: 100% (791/791), 11.21 MiB | 18.91 MiB/s, done.\n",
            "Resolving deltas: 100% (460/460), done.\n",
            "/content/efficientdet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --help"
      ],
      "metadata": {
        "id": "NN7pFnMR1stL",
        "outputId": "71478563-f82b-4352-b7ee-17691c2fc6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py [-h] [--dataset {VOC,COCO}] [--dataset_root DATASET_ROOT] [--network NETWORK]\n",
            "                [--resume RESUME] [--num_epoch NUM_EPOCH] [--batch_size BATCH_SIZE]\n",
            "                [--num_class NUM_CLASS] [--device DEVICE]\n",
            "                [--grad_accumulation_steps GRAD_ACCUMULATION_STEPS] [--lr LR]\n",
            "                [--momentum MOMENTUM] [--weight_decay WEIGHT_DECAY] [--gamma GAMMA]\n",
            "                [--save_folder SAVE_FOLDER] [-j N] [--start_epoch N] [--world-size WORLD_SIZE]\n",
            "                [--rank RANK] [--dist-url DIST_URL] [--dist-backend DIST_BACKEND] [--seed SEED]\n",
            "                [--gpu GPU] [--multiprocessing-distributed]\n",
            "\n",
            "PyTorch ImageNet Training\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --dataset {VOC,COCO}  VOC or COCO\n",
            "  --dataset_root DATASET_ROOT\n",
            "                        Dataset root directory path [/root/data/VOCdevkit/, /root/data/coco/]\n",
            "  --network NETWORK     efficientdet-[d0, d1, ..]\n",
            "  --resume RESUME       Checkpoint state_dict file to resume training from\n",
            "  --num_epoch NUM_EPOCH\n",
            "                        Num epoch for training\n",
            "  --batch_size BATCH_SIZE\n",
            "                        Batch size for training\n",
            "  --num_class NUM_CLASS\n",
            "                        Number of class used in model\n",
            "  --device DEVICE       Use CUDA to train model\n",
            "  --grad_accumulation_steps GRAD_ACCUMULATION_STEPS\n",
            "                        Number of gradient accumulation steps\n",
            "  --lr LR, --learning-rate LR\n",
            "                        initial learning rate\n",
            "  --momentum MOMENTUM   Momentum value for optim\n",
            "  --weight_decay WEIGHT_DECAY\n",
            "                        Weight decay for SGD\n",
            "  --gamma GAMMA         Gamma update for SGD\n",
            "  --save_folder SAVE_FOLDER\n",
            "                        Directory for saving checkpoint models\n",
            "  -j N, --workers N     number of data loading workers (default: 4)\n",
            "  --start_epoch N       manual epoch number (useful on restarts)\n",
            "  --world-size WORLD_SIZE\n",
            "                        number of nodes for distributed training\n",
            "  --rank RANK           node rank for distributed training\n",
            "  --dist-url DIST_URL   url used to set up distributed training\n",
            "  --dist-backend DIST_BACKEND\n",
            "                        distributed backend\n",
            "  --seed SEED           seed for initializing training.\n",
            "  --gpu GPU             GPU id to use.\n",
            "  --multiprocessing-distributed\n",
            "                        Use multi-processing distributed training to launch N processes per node,\n",
            "                        which has N GPUs. This is the fastest way to use PyTorch for either single\n",
            "                        node or multi node data parallel training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's|http://storage.googleapis.com/public-models/efficientnet/efficientnet-b0-355c32eb.pth|https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth|g' models/utils.py\n",
        "!python train.py --dataset COCO --dataset_root /content/data --network efficientdet-d0 --batch_size 32"
      ],
      "metadata": {
        "id": "Bl2LdhRhnPc0",
        "outputId": "13e7526a-98ff-412c-ea7d-23e6e5cd1ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/efficientdet/train.py:302: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.\n",
            "  warnings.warn('You have chosen to seed training. '\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
            "100% 20.4M/20.4M [00:00<00:00, 227MB/s]\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "Run with DataParallel ....\n",
            "0 epoch: \t start training....\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/efficientdet/train.py\", line 333, in <module>\n",
            "    main()\n",
            "  File \"/content/efficientdet/train.py\", line 329, in main\n",
            "    main_worker(args.gpu, ngpus_per_node, args)\n",
            "  File \"/content/efficientdet/train.py\", line 274, in main_worker\n",
            "    train(train_loader, model, scheduler, optimizer, epoch, args)\n",
            "  File \"/content/efficientdet/train.py\", line 107, in train\n",
            "    classification_loss, regression_loss = model([images, annotations])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\", line 183, in forward\n",
            "    return self.module(*inputs[0], **module_kwargs[0])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/efficientdet/models/efficientdet.py\", line 64, in forward\n",
            "    classification = torch.cat([out for out in outs[0]], dim=1)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 480.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 451.06 MiB is free. Process 2746 has 14.30 GiB memory in use. Of the allocated memory 14.12 GiB is allocated by PyTorch, and 59.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    }
  ]
}